{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "198c699a-e1e8-4f8b-8cd5-98a1d05f7ec3",
      "metadata": {
        "scrolled": true,
        "id": "198c699a-e1e8-4f8b-8cd5-98a1d05f7ec3"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torchvision\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader, BatchSampler, random_split\n",
        "from torchvision import transforms\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import shutil\n",
        "\n",
        "# Copy train_images folder from Drive to local fast disk\n",
        "!cp -r /content/drive/MyDrive/nndl_colab/data/train_images /content/train_images\n",
        "data_dir = '/content/drive/MyDrive/nndl_colab/data'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxoDffCKROxw",
        "outputId": "4f388536-4fb6-426e-a967-f3526f90dbaa"
      },
      "id": "TxoDffCKROxw",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_blended_novel_images(ann_df, img_dir, output_dir, num_samples_each=250):\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    novel_ann = []\n",
        "\n",
        "    to_tensor = ToTensor()\n",
        "    to_pil = ToPILImage()\n",
        "\n",
        "    ann_df['superclass_index'] = ann_df['superclass_index'].astype(int)\n",
        "    ann_df['subclass_index'] = ann_df['subclass_index'].astype(int)\n",
        "\n",
        "    novel_super_idx = 3\n",
        "    novel_sub_idx = 87\n",
        "\n",
        "    for novel_type in ['sub_novel', 'super_novel']:\n",
        "        for i in range(num_samples_each):\n",
        "            if novel_type == 'sub_novel':\n",
        "                super_cls = random.choice(ann_df['superclass_index'].unique())\n",
        "                subset = ann_df[ann_df['superclass_index'] == super_cls]\n",
        "                unique_subs = subset['subclass_index'].unique()\n",
        "                if len(unique_subs) < 2:\n",
        "                    continue\n",
        "\n",
        "                rows = []\n",
        "                seen_subclasses = set()\n",
        "                while len(rows) < 2:\n",
        "                    idx = random.randint(0, len(subset) - 1)\n",
        "                    row = subset.iloc[idx]\n",
        "                    if row['subclass_index'] not in seen_subclasses:\n",
        "                        rows.append(row)\n",
        "                        seen_subclasses.add(row['subclass_index'])\n",
        "\n",
        "                tag = 'subnovel'\n",
        "\n",
        "            else:  # super_novel\n",
        "                rows = []\n",
        "                seen_superclasses = set()\n",
        "                while len(rows) < 2:\n",
        "                    idx = random.randint(0, len(ann_df) - 1)\n",
        "                    row = ann_df.iloc[idx]\n",
        "                    if row['superclass_index'] not in seen_superclasses:\n",
        "                        rows.append(row)\n",
        "                        seen_superclasses.add(row['superclass_index'])\n",
        "\n",
        "                tag = 'supernovel'\n",
        "\n",
        "            imgs = [to_tensor(Image.open(os.path.join(img_dir, row['image'])).convert('RGB')) for row in rows]\n",
        "\n",
        "            blended = (imgs[0] + imgs[1]) / 2\n",
        "            blended = torch.clamp(blended, 0, 1)\n",
        "\n",
        "            filename = f\"blend_{tag}_{i}.jpg\"\n",
        "            to_pil(blended).save(os.path.join(output_dir, filename))\n",
        "\n",
        "            novel_ann.append({\n",
        "                'image': filename,\n",
        "                'superclass_index': novel_super_idx if tag == 'supernovel' else super_cls,\n",
        "                'subclass_index': novel_sub_idx,\n",
        "                'is_super_novel': 1 if tag == 'supernovel' else 0,\n",
        "                'is_sub_novel': 1\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(novel_ann)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "D_Z-NxhcIjdM"
      },
      "id": "D_Z-NxhcIjdM",
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "\n",
        "# Load base data\n",
        "train_ann_df = pd.read_csv(f'{data_dir}/train_data.csv')\n",
        "test_ann_df = pd.read_csv(f'{data_dir}/train_data.csv')  # If no test split\n",
        "super_map_df = pd.read_csv(f'{data_dir}/superclass_mapping.csv')\n",
        "sub_map_df = pd.read_csv(f'{data_dir}/subclass_mapping.csv')\n",
        "\n",
        "# Image paths\n",
        "train_img_dir = '/content/train_images'\n",
        "test_img_dir = '/content/train_images'\n",
        "\n",
        "# Image transform\n",
        "image_preprocessing = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5] * 3, [0.5] * 3)\n",
        "])\n",
        "\n",
        "\n",
        "novel_df = generate_blended_novel_images(\n",
        "    ann_df=train_ann_df,\n",
        "    img_dir=train_img_dir,\n",
        "    output_dir='/content/novel_blended_images',\n",
        "    num_samples_each=250\n",
        ")\n",
        "#"
      ],
      "metadata": {
        "id": "p3l424a5Iuwl"
      },
      "id": "p3l424a5Iuwl",
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Annotate original data as \"known\"\n",
        "train_ann_df['is_super_novel'] = 0\n",
        "train_ann_df['is_sub_novel'] = 0\n",
        "\n",
        "# Merge known and novel data\n",
        "combined_ann_df = pd.concat([train_ann_df, novel_df], ignore_index=True)\n",
        "\n"
      ],
      "metadata": {
        "id": "Fvlk1JddWj9P"
      },
      "id": "Fvlk1JddWj9P",
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "c370d643-46fd-4d03-bb17-a875e79d5e2c",
      "metadata": {
        "id": "c370d643-46fd-4d03-bb17-a875e79d5e2c"
      },
      "outputs": [],
      "source": [
        "# Create Dataset class for multilabel classification\n",
        "class MultiClassImageDataset(Dataset):\n",
        "    def __init__(self, ann_df, super_map_df, sub_map_df, img_dir, transform=None):\n",
        "        self.ann_df = ann_df\n",
        "        self.super_map_df = super_map_df\n",
        "        self.sub_map_df = sub_map_df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ann_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.ann_df['image'][idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        super_idx = self.ann_df['superclass_index'][idx]\n",
        "        super_label = self.super_map_df['class'][super_idx]\n",
        "\n",
        "        sub_idx = self.ann_df['subclass_index'][idx]\n",
        "        sub_label = self.sub_map_df['class'][sub_idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, super_idx, super_label, sub_idx, sub_label\n",
        "\n",
        "class MultiClassImageTestDataset(Dataset):\n",
        "    def __init__(self, super_map_df, sub_map_df, img_dir, transform=None):\n",
        "        self.super_map_df = super_map_df\n",
        "        self.sub_map_df = sub_map_df\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self): # Count files in img_dir\n",
        "        return len([fname for fname in os.listdir(self.img_dir)])\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      try:\n",
        "          img_name = self.ann_df['image'].iloc[int(idx)]\n",
        "          img_path = os.path.join(self.img_dir, img_name)\n",
        "\n",
        "          if not os.path.exists(img_path):\n",
        "              raise FileNotFoundError(f\"âŒ Image not found: {img_path}\")\n",
        "\n",
        "          image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "          super_idx = int(self.ann_df['superclass_index'].iloc[int(idx)])\n",
        "          super_label = self.super_map_df['class'].iloc[super_idx]\n",
        "\n",
        "          sub_idx = int(self.ann_df['subclass_index'].iloc[int(idx)])\n",
        "          sub_label = self.sub_map_df['class'].iloc[sub_idx]\n",
        "\n",
        "          if self.transform:\n",
        "              image = self.transform(image)\n",
        "\n",
        "          return image, super_idx, super_label, sub_idx, sub_label\n",
        "\n",
        "      except Exception as e:\n",
        "          print(f\"â— Error at idx {idx}: {e}\")\n",
        "          raise e  # re-raise so DataLoader stops with full traceback\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "\n",
        "class MultiClassImageDatasetWithNovelty(Dataset):\n",
        "    def __init__(self, ann_df, super_map_df, sub_map_df, transform=None):\n",
        "        self.ann_df = ann_df\n",
        "        self.super_map_df = super_map_df\n",
        "        self.sub_map_df = sub_map_df\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.ann_df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        row = self.ann_df.iloc[idx]\n",
        "        filename = row['image']\n",
        "\n",
        "        # Determine image location\n",
        "        if filename.startswith(\"blend_\"):\n",
        "            img_path = os.path.join('/content/novel_blended_images', filename)\n",
        "        else:\n",
        "            img_path = os.path.join('/content/train_images', filename)\n",
        "\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        super_idx = int(row['superclass_index'])\n",
        "        sub_idx = int(row['subclass_index'])\n",
        "        is_super_novel = int(row.get('is_super_novel', 0))\n",
        "        is_sub_novel = int(row.get('is_sub_novel', 0))\n",
        "\n",
        "        return image, super_idx, sub_idx, is_super_novel, is_sub_novel\n",
        "\n"
      ],
      "metadata": {
        "id": "8HcC6gyMJVaB"
      },
      "id": "8HcC6gyMJVaB",
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "# Combined annotation already includes known + super-novel + sub-novel\n",
        "full_dataset = MultiClassImageDatasetWithNovelty(\n",
        "    ann_df=combined_ann_df,\n",
        "    super_map_df=super_map_df,\n",
        "    sub_map_df=sub_map_df,\n",
        "    transform=image_preprocessing\n",
        ")\n",
        "\n",
        "# Fix randomness for reproducibility\n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Define split sizes\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = int(0.1 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size - val_size\n",
        "\n",
        "# Perform the split\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    full_dataset, [train_size, val_size, test_size]\n",
        ")\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "KJk0ZtLYJat4"
      },
      "id": "KJk0ZtLYJat4",
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class ViTMultiTaskWithNovelty(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.base = timm.create_model('vit_base_patch32_224', pretrained=True)\n",
        "        self.base.head = nn.Identity()\n",
        "\n",
        "        # Main classification heads\n",
        "        self.super_head = nn.Linear(self.base.num_features, 4)\n",
        "        self.sub_head = nn.Linear(self.base.num_features, 88)\n",
        "\n",
        "        # Novelty detection heads\n",
        "        self.super_novel_head = nn.Linear(self.base.num_features, 1)  # detects novel superclass\n",
        "        self.sub_novel_head = nn.Linear(self.base.num_features, 1)    # detects novel subclass\n",
        "\n",
        "        # Freeze base model\n",
        "        for param in self.base.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        # Unfreeze last 2 blocks + norm\n",
        "        for name, param in self.base.named_parameters():\n",
        "            if \"blocks.10\" in name or \"blocks.11\" in name or \"norm\" in name:\n",
        "                param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.base(x)\n",
        "        return (\n",
        "            self.super_head(feats),         # logits for superclass\n",
        "            self.sub_head(feats),           # logits for subclass\n",
        "            self.super_novel_head(feats),   # binary novelty score\n",
        "            self.sub_novel_head(feats)      # binary novelty score\n",
        "        )\n",
        "\n",
        "# Device setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = ViTMultiTaskWithNovelty().to(device)\n",
        "\n"
      ],
      "metadata": {
        "id": "qUBWaQcyUyAt"
      },
      "id": "qUBWaQcyUyAt",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Separate head and unfreezed backbone params\n",
        "head_params = (\n",
        "    list(model.super_head.parameters()) +\n",
        "    list(model.sub_head.parameters()) +\n",
        "    list(model.super_novel_head.parameters()) +\n",
        "    list(model.sub_novel_head.parameters())\n",
        ")\n",
        "\n",
        "backbone_params = [\n",
        "    p for n, p in model.named_parameters()\n",
        "    if \"blocks.10\" in n or \"blocks.11\" in n or \"norm\" in n\n",
        "]\n",
        "\n",
        "optimizer = torch.optim.AdamW([\n",
        "    {'params': head_params, 'lr': 1e-3},\n",
        "    {'params': backbone_params, 'lr': 1e-5}\n",
        "])\n",
        "\n",
        "# Losses\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "super_novel_criterion = nn.BCEWithLogitsLoss()\n",
        "sub_novel_criterion = nn.BCEWithLogitsLoss()\n",
        "\n"
      ],
      "metadata": {
        "id": "xjk4y7ajJ6FZ"
      },
      "id": "xjk4y7ajJ6FZ",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "ebdf524a-98bf-4d0b-9b63-2b2b7b87daa1",
      "metadata": {
        "id": "ebdf524a-98bf-4d0b-9b63-2b2b7b87daa1"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def train_and_validate(model, train_loader, val_loader, optimizer,\n",
        "                       criterion, super_novel_criterion, sub_novel_criterion,\n",
        "                       device, num_epochs=10):\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n Epoch {epoch+1}/{num_epochs}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        # ---- TRAIN ----\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        correct_super_train, correct_sub_train = 0, 0\n",
        "        correct_supernovel_train, correct_subnovel_train = 0, 0\n",
        "        total_train = 0\n",
        "\n",
        "        for i, (images, super_idx, sub_idx, is_super_novel, is_sub_novel) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            super_idx = super_idx.to(device)\n",
        "            sub_idx = sub_idx.to(device)\n",
        "            is_super_novel = is_super_novel.float().to(device)\n",
        "            is_sub_novel = is_sub_novel.float().to(device)\n",
        "\n",
        "            out_super, out_sub, out_super_novel, out_sub_novel = model(images)\n",
        "\n",
        "            loss = (\n",
        "                criterion(out_super, super_idx) +\n",
        "                criterion(out_sub, sub_idx) +\n",
        "                super_novel_criterion(out_super_novel.squeeze(), is_super_novel) +\n",
        "                sub_novel_criterion(out_sub_novel.squeeze(), is_sub_novel)\n",
        "            )\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Accuracy\n",
        "            pred_super = out_super.argmax(1)\n",
        "            pred_sub = out_sub.argmax(1)\n",
        "            pred_supernovel = (torch.sigmoid(out_super_novel.squeeze()) > 0.5).long()\n",
        "            pred_subnovel = (torch.sigmoid(out_sub_novel.squeeze()) > 0.5).long()\n",
        "\n",
        "            correct_super_train += (pred_super == super_idx).sum().item()\n",
        "            correct_sub_train += (pred_sub == sub_idx).sum().item()\n",
        "            correct_supernovel_train += (pred_supernovel == is_super_novel.long()).sum().item()\n",
        "            correct_subnovel_train += (pred_subnovel == is_sub_novel.long()).sum().item()\n",
        "\n",
        "            total_train += images.size(0)\n",
        "            train_loss += loss.item()\n",
        "\n",
        "            #print(f\"[Train Batch {i+1}] Loss: {loss.item():.4f} | Super Acc: {correct_super_train/total_train:.4f} | Sub Acc: {correct_sub_train/total_train:.4f} | SuperNovel Acc: {correct_supernovel_train/total_train:.4f} | SubNovel Acc: {correct_subnovel_train/total_train:.4f}\")\n",
        "\n",
        "        print(f\" Epoch {epoch+1} Train Summary: Loss = {train_loss/len(train_loader):.4f} | Super Acc = {correct_super_train/total_train:.4f} | Sub Acc = {correct_sub_train/total_train:.4f} | SuperNovel Acc = {correct_supernovel_train/total_train:.4f} | SubNovel Acc = {correct_subnovel_train/total_train:.4f}\")\n",
        "\n",
        "        # ---- VALIDATION ----\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct_super_val, correct_sub_val = 0, 0\n",
        "        correct_supernovel_val, correct_subnovel_val = 0, 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, (images, super_idx, sub_idx, is_super_novel, is_sub_novel) in enumerate(val_loader):\n",
        "                images = images.to(device)\n",
        "                super_idx = super_idx.to(device)\n",
        "                sub_idx = sub_idx.to(device)\n",
        "                is_super_novel = is_super_novel.float().to(device)\n",
        "                is_sub_novel = is_sub_novel.float().to(device)\n",
        "\n",
        "                out_super, out_sub, out_super_novel, out_sub_novel = model(images)\n",
        "\n",
        "                loss = (\n",
        "                    criterion(out_super, super_idx) +\n",
        "                    criterion(out_sub, sub_idx) +\n",
        "                    super_novel_criterion(out_super_novel.squeeze(), is_super_novel) +\n",
        "                    sub_novel_criterion(out_sub_novel.squeeze(), is_sub_novel)\n",
        "                )\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                pred_super = out_super.argmax(1)\n",
        "                pred_sub = out_sub.argmax(1)\n",
        "                pred_supernovel = (torch.sigmoid(out_super_novel.squeeze()) > 0.5).long()\n",
        "                pred_subnovel = (torch.sigmoid(out_sub_novel.squeeze()) > 0.5).long()\n",
        "\n",
        "                correct_super_val += (pred_super == super_idx).sum().item()\n",
        "                correct_sub_val += (pred_sub == sub_idx).sum().item()\n",
        "                correct_supernovel_val += (pred_supernovel == is_super_novel.long()).sum().item()\n",
        "                correct_subnovel_val += (pred_subnovel == is_sub_novel.long()).sum().item()\n",
        "\n",
        "                total_val += images.size(0)\n",
        "\n",
        "                #print(f\"[Val Batch {i+1}] Loss: {loss.item():.4f} | Super Acc: {correct_super_val/total_val:.4f} | Sub Acc: {correct_sub_val/total_val:.4f} | SuperNovel Acc: {correct_supernovel_val/total_val:.4f} | SubNovel Acc: {correct_subnovel_val/total_val:.4f}\")\n",
        "\n",
        "        print(f\" Epoch {epoch+1} Val Summary: Loss = {val_loss/len(val_loader):.4f} | Super Acc = {correct_super_val/total_val:.4f} | Sub Acc = {correct_sub_val/total_val:.4f} | SuperNovel Acc = {correct_supernovel_val/total_val:.4f} | SubNovel Acc = {correct_subnovel_val/total_val:.4f}\")\n",
        "        print(f\"Time: {time.time() - start_time:.2f}s\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#15 is best for now\n",
        "train_and_validate(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer,\n",
        "    criterion,               # CrossEntropyLoss (shared)\n",
        "    super_novel_criterion,   # BCEWithLogitsLoss for super_novel\n",
        "    sub_novel_criterion,     # BCEWithLogitsLoss for sub_novel\n",
        "    device,\n",
        "    num_epochs=15\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJPFvP6Ob5Z_",
        "outputId": "fbf260d6-402e-4431-f1a5-7c4d90a07ade"
      },
      "id": "ZJPFvP6Ob5Z_",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1/15\n",
            " Epoch 1 Train Summary: Loss = 0.1929 | Super Acc = 0.9912 | Sub Acc = 0.9773 | SuperNovel Acc = 0.9816 | SubNovel Acc = 0.9976\n",
            " Epoch 1 Val Summary: Loss = 0.1874 | Super Acc = 0.9882 | Sub Acc = 0.9705 | SuperNovel Acc = 0.9838 | SubNovel Acc = 0.9971\n",
            "Time: 15.82s\n",
            "\n",
            " Epoch 2/15\n",
            " Epoch 2 Train Summary: Loss = 0.1176 | Super Acc = 0.9956 | Sub Acc = 0.9886 | SuperNovel Acc = 0.9843 | SubNovel Acc = 0.9993\n",
            " Epoch 2 Val Summary: Loss = 0.1799 | Super Acc = 0.9912 | Sub Acc = 0.9646 | SuperNovel Acc = 0.9823 | SubNovel Acc = 0.9985\n",
            "Time: 15.68s\n",
            "\n",
            " Epoch 3/15\n",
            " Epoch 3 Train Summary: Loss = 0.0796 | Super Acc = 0.9993 | Sub Acc = 0.9932 | SuperNovel Acc = 0.9897 | SubNovel Acc = 0.9998\n",
            " Epoch 3 Val Summary: Loss = 0.1568 | Super Acc = 0.9882 | Sub Acc = 0.9735 | SuperNovel Acc = 0.9838 | SubNovel Acc = 1.0000\n",
            "Time: 15.60s\n",
            "\n",
            " Epoch 4/15\n",
            " Epoch 4 Train Summary: Loss = 0.0527 | Super Acc = 0.9998 | Sub Acc = 0.9972 | SuperNovel Acc = 0.9932 | SubNovel Acc = 1.0000\n",
            " Epoch 4 Val Summary: Loss = 0.1430 | Super Acc = 0.9882 | Sub Acc = 0.9808 | SuperNovel Acc = 0.9853 | SubNovel Acc = 1.0000\n",
            "Time: 15.89s\n",
            "\n",
            " Epoch 5/15\n",
            " Epoch 5 Train Summary: Loss = 0.0375 | Super Acc = 1.0000 | Sub Acc = 0.9994 | SuperNovel Acc = 0.9965 | SubNovel Acc = 1.0000\n",
            " Epoch 5 Val Summary: Loss = 0.1342 | Super Acc = 0.9882 | Sub Acc = 0.9794 | SuperNovel Acc = 0.9853 | SubNovel Acc = 1.0000\n",
            "Time: 15.94s\n",
            "\n",
            " Epoch 6/15\n",
            " Epoch 6 Train Summary: Loss = 0.0279 | Super Acc = 1.0000 | Sub Acc = 0.9998 | SuperNovel Acc = 0.9982 | SubNovel Acc = 1.0000\n",
            " Epoch 6 Val Summary: Loss = 0.1389 | Super Acc = 0.9882 | Sub Acc = 0.9705 | SuperNovel Acc = 0.9853 | SubNovel Acc = 1.0000\n",
            "Time: 15.70s\n",
            "\n",
            " Epoch 7/15\n",
            " Epoch 7 Train Summary: Loss = 0.0209 | Super Acc = 1.0000 | Sub Acc = 0.9998 | SuperNovel Acc = 0.9996 | SubNovel Acc = 1.0000\n",
            " Epoch 7 Val Summary: Loss = 0.1368 | Super Acc = 0.9897 | Sub Acc = 0.9779 | SuperNovel Acc = 0.9853 | SubNovel Acc = 1.0000\n",
            "Time: 15.77s\n",
            "\n",
            " Epoch 8/15\n",
            " Epoch 8 Train Summary: Loss = 0.0158 | Super Acc = 1.0000 | Sub Acc = 1.0000 | SuperNovel Acc = 1.0000 | SubNovel Acc = 1.0000\n",
            " Epoch 8 Val Summary: Loss = 0.1329 | Super Acc = 0.9897 | Sub Acc = 0.9779 | SuperNovel Acc = 0.9882 | SubNovel Acc = 1.0000\n",
            "Time: 16.01s\n",
            "\n",
            " Epoch 9/15\n",
            " Epoch 9 Train Summary: Loss = 0.0125 | Super Acc = 1.0000 | Sub Acc = 1.0000 | SuperNovel Acc = 1.0000 | SubNovel Acc = 1.0000\n",
            " Epoch 9 Val Summary: Loss = 0.1346 | Super Acc = 0.9897 | Sub Acc = 0.9808 | SuperNovel Acc = 0.9867 | SubNovel Acc = 1.0000\n",
            "Time: 15.98s\n",
            "\n",
            " Epoch 10/15\n",
            " Epoch 10 Train Summary: Loss = 0.0101 | Super Acc = 1.0000 | Sub Acc = 1.0000 | SuperNovel Acc = 1.0000 | SubNovel Acc = 1.0000\n",
            " Epoch 10 Val Summary: Loss = 0.1351 | Super Acc = 0.9897 | Sub Acc = 0.9808 | SuperNovel Acc = 0.9867 | SubNovel Acc = 1.0000\n",
            "Time: 15.69s\n",
            "\n",
            " Epoch 11/15\n",
            " Epoch 11 Train Summary: Loss = 0.0083 | Super Acc = 1.0000 | Sub Acc = 1.0000 | SuperNovel Acc = 1.0000 | SubNovel Acc = 1.0000\n",
            " Epoch 11 Val Summary: Loss = 0.1387 | Super Acc = 0.9912 | Sub Acc = 0.9779 | SuperNovel Acc = 0.9867 | SubNovel Acc = 1.0000\n",
            "Time: 15.99s\n",
            "\n",
            " Epoch 12/15\n",
            " Epoch 12 Train Summary: Loss = 0.0070 | Super Acc = 1.0000 | Sub Acc = 1.0000 | SuperNovel Acc = 1.0000 | SubNovel Acc = 1.0000\n",
            " Epoch 12 Val Summary: Loss = 0.1366 | Super Acc = 0.9897 | Sub Acc = 0.9764 | SuperNovel Acc = 0.9867 | SubNovel Acc = 1.0000\n",
            "Time: 15.99s\n",
            "\n",
            " Epoch 13/15\n",
            " Epoch 13 Train Summary: Loss = 0.0059 | Super Acc = 1.0000 | Sub Acc = 1.0000 | SuperNovel Acc = 1.0000 | SubNovel Acc = 1.0000\n",
            " Epoch 13 Val Summary: Loss = 0.1386 | Super Acc = 0.9882 | Sub Acc = 0.9779 | SuperNovel Acc = 0.9853 | SubNovel Acc = 1.0000\n",
            "Time: 15.98s\n",
            "\n",
            " Epoch 14/15\n",
            " Epoch 14 Train Summary: Loss = 0.0051 | Super Acc = 1.0000 | Sub Acc = 1.0000 | SuperNovel Acc = 1.0000 | SubNovel Acc = 1.0000\n",
            " Epoch 14 Val Summary: Loss = 0.1371 | Super Acc = 0.9897 | Sub Acc = 0.9823 | SuperNovel Acc = 0.9853 | SubNovel Acc = 1.0000\n",
            "Time: 15.96s\n",
            "\n",
            " Epoch 15/15\n",
            " Epoch 15 Train Summary: Loss = 0.0044 | Super Acc = 1.0000 | Sub Acc = 1.0000 | SuperNovel Acc = 1.0000 | SubNovel Acc = 1.0000\n",
            " Epoch 15 Val Summary: Loss = 0.1392 | Super Acc = 0.9897 | Sub Acc = 0.9794 | SuperNovel Acc = 0.9853 | SubNovel Acc = 1.0000\n",
            "Time: 15.94s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "16d17e37-1a08-4ae1-8517-a16ff4769622",
      "metadata": {
        "id": "16d17e37-1a08-4ae1-8517-a16ff4769622"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct_super = 0\n",
        "    correct_sub = 0\n",
        "    correct_super_novel = 0\n",
        "    correct_sub_novel = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, super_idx, sub_idx, is_super_novel, is_sub_novel in dataloader:\n",
        "            images = images.to(device)\n",
        "            super_idx = super_idx.to(device)\n",
        "            sub_idx = sub_idx.to(device)\n",
        "            is_super_novel = is_super_novel.to(device)\n",
        "            is_sub_novel = is_sub_novel.to(device)\n",
        "\n",
        "            out_super, out_sub, out_super_novel, out_sub_novel = model(images)\n",
        "\n",
        "            pred_super = out_super.argmax(1)\n",
        "            pred_sub = out_sub.argmax(1)\n",
        "            pred_super_novel = (torch.sigmoid(out_super_novel.squeeze()) > 0.5).long()\n",
        "            pred_sub_novel = (torch.sigmoid(out_sub_novel.squeeze()) > 0.5).long()\n",
        "\n",
        "            correct_super += (pred_super == super_idx).sum().item()\n",
        "            correct_sub += (pred_sub == sub_idx).sum().item()\n",
        "            correct_super_novel += (pred_super_novel == is_super_novel.long()).sum().item()\n",
        "            correct_sub_novel += (pred_sub_novel == is_sub_novel.long()).sum().item()\n",
        "\n",
        "            total += images.size(0)\n",
        "\n",
        "    print(f\"   Evaluation Summary:\")\n",
        "    print(f\"   Superclass Accuracy      = {correct_super / total:.4f}\")\n",
        "    print(f\"   Subclass Accuracy        = {correct_sub / total:.4f}\")\n",
        "    print(f\"   Super Novelty Accuracy   = {correct_super_novel / total:.4f}\")\n",
        "    print(f\"   Sub Novelty Accuracy     = {correct_sub_novel / total:.4f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "6ab70fb9-6e14-49f1-b9bb-5f3da6807399",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ab70fb9-6e14-49f1-b9bb-5f3da6807399",
        "outputId": "ce11c54f-7648-4140-cb96-c882280696b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Evaluation Summary:\n",
            "   Superclass Accuracy      = 0.9897\n",
            "   Subclass Accuracy        = 0.9632\n",
            "   Super Novelty Accuracy   = 0.9824\n",
            "   Sub Novelty Accuracy     = 1.0000\n"
          ]
        }
      ],
      "source": [
        "evaluate(model, test_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SuperNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.base = timm.create_model('vit_base_patch32_224', pretrained=True)\n",
        "        self.base.head = nn.Identity()\n",
        "\n",
        "        self.super_head = nn.Linear(self.base.num_features, 4)\n",
        "        self.super_novel_head = nn.Linear(self.base.num_features, 1)\n",
        "\n",
        "        for param in self.base.parameters():\n",
        "            param.requires_grad = False\n",
        "        for name, param in self.base.named_parameters():\n",
        "            if any(f\"blocks.{i}\" in name for i in range(8, 12)) or \"norm\" in name:\n",
        "                param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.base(x)\n",
        "        return self.super_head(feats), self.super_novel_head(feats)\n"
      ],
      "metadata": {
        "id": "xxKz0zR9dJYJ"
      },
      "id": "xxKz0zR9dJYJ",
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SubNet(nn.Module):\n",
        "    def __init__(self, super_dim=4):\n",
        "        super().__init__()\n",
        "        self.base = timm.create_model('vit_base_patch32_224', pretrained=True)\n",
        "        self.base.head = nn.Identity()\n",
        "\n",
        "        self.input_proj = nn.Linear(self.base.num_features + super_dim, 512)\n",
        "        self.sub_head = nn.Linear(512, 88)\n",
        "        self.sub_novel_head = nn.Linear(512, 1)\n",
        "\n",
        "        for param in self.base.parameters():\n",
        "            param.requires_grad = False\n",
        "        for name, param in self.base.named_parameters():\n",
        "            if any(f\"blocks.{i}\" in name for i in range(8, 12)) or \"norm\" in name:\n",
        "                param.requires_grad = True\n",
        "\n",
        "    def forward(self, x, super_onehot):\n",
        "        feats = self.base(x)\n",
        "        combined = torch.cat([feats, super_onehot], dim=1)\n",
        "        hidden = self.input_proj(combined)\n",
        "        return self.sub_head(hidden), self.sub_novel_head(hidden)\n"
      ],
      "metadata": {
        "id": "AP5Ck_xreA0j"
      },
      "id": "AP5Ck_xreA0j",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "bce = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def train_two_stage(supernet, subnet, train_loader, optimizer_super, optimizer_sub, device, num_epochs=10):\n",
        "    supernet.train()\n",
        "    subnet.train()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nðŸ§ª Epoch {epoch+1}/{num_epochs}\")\n",
        "        total, correct_super, correct_sub = 0, 0, 0\n",
        "        correct_supernovel, correct_subnovel = 0, 0\n",
        "\n",
        "        for images, super_idx, sub_idx, is_super_novel, is_sub_novel in train_loader:\n",
        "            images = images.to(device)\n",
        "            super_idx = super_idx.to(device)\n",
        "            sub_idx = sub_idx.to(device)\n",
        "            is_super_novel = is_super_novel.float().to(device)\n",
        "            is_sub_novel = is_sub_novel.float().to(device)\n",
        "\n",
        "            # --- SuperNet forward ---\n",
        "            super_logits, super_novel = supernet(images)\n",
        "            super_loss = (\n",
        "                criterion(super_logits, super_idx) +\n",
        "                bce(super_novel.squeeze(), is_super_novel)\n",
        "            )\n",
        "            optimizer_super.zero_grad()\n",
        "            super_loss.backward()\n",
        "            optimizer_super.step()\n",
        "\n",
        "            # --- SubNet forward (teacher forcing with GT super_idx) ---\n",
        "            super_onehot = F.one_hot(super_idx, num_classes=4).float().to(device)\n",
        "            sub_logits, sub_novel = subnet(images, super_onehot)\n",
        "            sub_loss = (\n",
        "                criterion(sub_logits, sub_idx) +\n",
        "                bce(sub_novel.squeeze(), is_sub_novel)\n",
        "            )\n",
        "            optimizer_sub.zero_grad()\n",
        "            sub_loss.backward()\n",
        "            optimizer_sub.step()\n",
        "\n",
        "            # --- Metrics ---\n",
        "            pred_super = super_logits.argmax(1)\n",
        "            pred_sub = sub_logits.argmax(1)\n",
        "            pred_supernovel = (torch.sigmoid(super_novel.squeeze()) > 0.5).long()\n",
        "            pred_subnovel = (torch.sigmoid(sub_novel.squeeze()) > 0.5).long()\n",
        "\n",
        "            correct_super += (pred_super == super_idx).sum().item()\n",
        "            correct_sub += (pred_sub == sub_idx).sum().item()\n",
        "            correct_supernovel += (pred_supernovel == is_super_novel.long()).sum().item()\n",
        "            correct_subnovel += (pred_subnovel == is_sub_novel.long()).sum().item()\n",
        "            total += images.size(0)\n",
        "\n",
        "        print(f\" Super Acc = {correct_super/total:.4f} | Sub Acc = {correct_sub/total:.4f}\")\n",
        "        print(f\" SuperNovel Acc = {correct_supernovel/total:.4f} | SubNovel Acc = {correct_subnovel/total:.4f}\")\n"
      ],
      "metadata": {
        "id": "oworiFkWeT98"
      },
      "id": "oworiFkWeT98",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_two_stage(supernet, subnet, dataloader, device):\n",
        "    supernet.eval()\n",
        "    subnet.eval()\n",
        "\n",
        "    total, correct_super, correct_sub = 0, 0, 0\n",
        "    correct_supernovel, correct_subnovel = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, super_idx, sub_idx, is_super_novel, is_sub_novel in dataloader:\n",
        "            images = images.to(device)\n",
        "            super_idx = super_idx.to(device)\n",
        "            sub_idx = sub_idx.to(device)\n",
        "            is_super_novel = is_super_novel.to(device)\n",
        "            is_sub_novel = is_sub_novel.to(device)\n",
        "\n",
        "            super_logits, super_novel = supernet(images)\n",
        "            pred_super = torch.argmax(super_logits, dim=1)\n",
        "\n",
        "            # Use predicted superclass for inference\n",
        "            super_onehot = F.one_hot(pred_super, num_classes=4).float()\n",
        "            sub_logits, sub_novel = subnet(images, super_onehot.to(device))\n",
        "            pred_sub = torch.argmax(sub_logits, dim=1)\n",
        "\n",
        "            pred_supernovel = (torch.sigmoid(super_novel.squeeze()) > 0.5).long()\n",
        "            pred_subnovel = (torch.sigmoid(sub_novel.squeeze()) > 0.5).long()\n",
        "\n",
        "            correct_super += (pred_super == super_idx).sum().item()\n",
        "            correct_sub += (pred_sub == sub_idx).sum().item()\n",
        "            correct_supernovel += (pred_supernovel == is_super_novel.long()).sum().item()\n",
        "            correct_subnovel += (pred_subnovel == is_sub_novel.long()).sum().item()\n",
        "            total += images.size(0)\n",
        "\n",
        "    print(f\" EVAL: Super Acc = {correct_super/total:.4f} | Sub Acc = {correct_sub/total:.4f}\")\n",
        "    print(f\"          SuperNovel Acc = {correct_supernovel/total:.4f} | SubNovel Acc = {correct_subnovel/total:.4f}\")\n"
      ],
      "metadata": {
        "id": "6Fflg019ebEm"
      },
      "id": "6Fflg019ebEm",
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "supernet = SuperNet().to(device)\n",
        "subnet = SubNet().to(device)\n",
        "\n",
        "optimizer_super = torch.optim.AdamW(supernet.parameters(), lr=1e-4)\n",
        "optimizer_sub = torch.optim.AdamW(subnet.parameters(), lr=1e-4)\n",
        "\n",
        "train_two_stage(supernet, subnet, train_loader, optimizer_super, optimizer_sub, device, num_epochs=5)\n",
        "\n"
      ],
      "metadata": {
        "id": "FrmAAAkMeeom"
      },
      "id": "FrmAAAkMeeom",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_two_stage(supernet, subnet, test_loader, device)"
      ],
      "metadata": {
        "id": "jVszhLiOeiW2"
      },
      "id": "jVszhLiOeiW2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!cp -r /content/drive/MyDrive/nndl_colab/data/test_images /content/test_images"
      ],
      "metadata": {
        "id": "00VqFu5SAVEP"
      },
      "id": "00VqFu5SAVEP",
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_1stage(model, test_loader, device, save_to_csv=True, save_path='test_predictions.csv'):\n",
        "    model.eval()\n",
        "    test_predictions = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
        "\n",
        "    novel_super_idx = 3\n",
        "    novel_sub_idx = 87\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, img_names) in enumerate(test_loader):\n",
        "            images = images.to(device)\n",
        "\n",
        "            super_logits, sub_logits, super_novel_logits, sub_novel_logits = model(images)\n",
        "\n",
        "            super_pred = torch.argmax(super_logits, dim=1).item()\n",
        "            sub_pred = torch.argmax(sub_logits, dim=1).item()\n",
        "\n",
        "            super_novel_score = torch.sigmoid(super_novel_logits.squeeze()).item()\n",
        "            sub_novel_score = torch.sigmoid(sub_novel_logits.squeeze()).item()\n",
        "\n",
        "            if super_novel_score > 0.5:\n",
        "                final_super = novel_super_idx\n",
        "                final_sub = novel_sub_idx\n",
        "            elif sub_novel_score > 0.5:\n",
        "                final_super = super_pred\n",
        "                final_sub = novel_sub_idx\n",
        "            else:\n",
        "                final_super = super_pred\n",
        "                final_sub = sub_pred\n",
        "\n",
        "            test_predictions['image'].append(img_names[0])\n",
        "            test_predictions['superclass_index'].append(final_super)\n",
        "            test_predictions['subclass_index'].append(final_sub)\n",
        "\n",
        "    test_predictions = pd.DataFrame(test_predictions)\n",
        "\n",
        "    if save_to_csv:\n",
        "        test_predictions.to_csv(save_path, index=False)\n",
        "        print(f\" Test predictions saved to {save_path}\")\n",
        "\n",
        "    return test_predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "vUsfJ_OfG2Z8"
      },
      "id": "vUsfJ_OfG2Z8",
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TestImageDataset(Dataset):\n",
        "    def __init__(self, img_dir, transform=None):\n",
        "        self.img_dir = img_dir\n",
        "        self.image_files = sorted(os.listdir(img_dir))\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = self.image_files[idx]\n",
        "        img_path = os.path.join(self.img_dir, img_name)\n",
        "        image = Image.open(img_path).convert('RGB')\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, img_name\n"
      ],
      "metadata": {
        "id": "7shVDs09HcLX"
      },
      "id": "7shVDs09HcLX",
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "open_set_test_dataset = TestImageDataset(img_dir='/content/test_images', transform=image_preprocessing)\n",
        "\n",
        "open_set_test_loader = DataLoader(\n",
        "    open_set_test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "zAtNChs_HhQp"
      },
      "id": "zAtNChs_HhQp",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = test_model_1stage(model, open_set_test_loader, device, save_to_csv=True, save_path='test_predictions_one_stage_ViT.csv')"
      ],
      "metadata": {
        "id": "r3Ej_SLHG5ic"
      },
      "id": "r3Ej_SLHG5ic",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test_model_2stage(supernet, subnet, test_loader, device, save_to_csv=True, save_path='test_predictions.csv'):\n",
        "    supernet.eval()\n",
        "    subnet.eval()\n",
        "    test_predictions = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
        "\n",
        "    novel_super_idx = 3\n",
        "    novel_sub_idx = 87\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, img_names) in enumerate(test_loader):\n",
        "            images = images.to(device)\n",
        "\n",
        "            super_logits, super_novel_logits = supernet(images)\n",
        "            super_pred = torch.argmax(super_logits, dim=1)\n",
        "\n",
        "            super_novel_score = torch.sigmoid(super_novel_logits.squeeze()).item()\n",
        "\n",
        "            if super_novel_score > 0.5:\n",
        "                final_super = novel_super_idx\n",
        "                final_sub = novel_sub_idx\n",
        "            else:\n",
        "                super_onehot = torch.nn.functional.one_hot(super_pred, num_classes=4).float()\n",
        "                sub_logits, sub_novel_logits = subnet(images, super_onehot.to(device))\n",
        "                sub_pred = torch.argmax(sub_logits, dim=1)\n",
        "\n",
        "                sub_novel_score = torch.sigmoid(sub_novel_logits.squeeze()).item()\n",
        "\n",
        "                if sub_novel_score > 0.5:\n",
        "                    final_super = super_pred.item()\n",
        "                    final_sub = novel_sub_idx\n",
        "                else:\n",
        "                    final_super = super_pred.item()\n",
        "                    final_sub = sub_pred.item()\n",
        "\n",
        "            test_predictions['image'].append(img_names[0])\n",
        "            test_predictions['superclass_index'].append(final_super)\n",
        "            test_predictions['subclass_index'].append(final_sub)\n",
        "\n",
        "    test_predictions = pd.DataFrame(test_predictions)\n",
        "\n",
        "    if save_to_csv:\n",
        "        test_predictions.to_csv(save_path, index=False)\n",
        "        print(f\" Test predictions saved to {save_path}\")\n",
        "\n",
        "    return test_predictions\n"
      ],
      "metadata": {
        "id": "vq63HeR6NEmi"
      },
      "id": "vq63HeR6NEmi",
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = test_model_2stage(\n",
        "    supernet,\n",
        "    subnet,\n",
        "    open_set_test_loader,\n",
        "    device,\n",
        "    save_to_csv=True,\n",
        "    save_path='test_predictions_2stage.csv'\n",
        ")\n"
      ],
      "metadata": {
        "id": "UsfqjNdfNGdT"
      },
      "id": "UsfqjNdfNGdT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def test_model_1stage_with_softmax_threshold(model, test_loader, device, threshold=0.7, save_to_csv=True, save_path='test_predictions.csv'):\n",
        "    model.eval()\n",
        "    test_predictions = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
        "\n",
        "    novel_super_idx = 3\n",
        "    novel_sub_idx = 87\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, img_names) in enumerate(test_loader):\n",
        "            images = images.to(device)\n",
        "\n",
        "            super_logits, sub_logits, super_novel_logits, sub_novel_logits = model(images)\n",
        "\n",
        "            super_probs = F.softmax(super_logits, dim=1)\n",
        "            sub_probs = F.softmax(sub_logits, dim=1)\n",
        "\n",
        "            super_max_prob, super_pred = torch.max(super_probs, dim=1)\n",
        "            sub_max_prob, sub_pred = torch.max(sub_probs, dim=1)\n",
        "\n",
        "            super_novel_score = torch.sigmoid(super_novel_logits.squeeze()).item()\n",
        "            sub_novel_score = torch.sigmoid(sub_novel_logits.squeeze()).item()\n",
        "\n",
        "            if super_max_prob.item() < threshold or super_novel_score > 0.5:\n",
        "                final_super = novel_super_idx\n",
        "                final_sub = novel_sub_idx\n",
        "            elif sub_max_prob.item() < threshold or sub_novel_score > 0.5:\n",
        "                final_super = super_pred.item()\n",
        "                final_sub = novel_sub_idx\n",
        "            else:\n",
        "                final_super = super_pred.item()\n",
        "                final_sub = sub_pred.item()\n",
        "\n",
        "            test_predictions['image'].append(img_names[0])\n",
        "            test_predictions['superclass_index'].append(final_super)\n",
        "            test_predictions['subclass_index'].append(final_sub)\n",
        "\n",
        "    test_predictions = pd.DataFrame(test_predictions)\n",
        "\n",
        "    if save_to_csv:\n",
        "        test_predictions.to_csv(save_path, index=False)\n",
        "        print(f\" Test predictions saved to {save_path}\")\n",
        "\n",
        "    return test_predictions\n"
      ],
      "metadata": {
        "id": "xoSJZ4Lxd3yS"
      },
      "id": "xoSJZ4Lxd3yS",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = test_model_1stage_with_softmax_threshold(\n",
        "    model,\n",
        "    open_set_test_loader,\n",
        "    device,\n",
        "    threshold=0.8,\n",
        "    save_to_csv=True,\n",
        "    save_path='1_stage_thresholded.csv'\n",
        ")\n"
      ],
      "metadata": {
        "id": "ClpQGQKjd5KC"
      },
      "id": "ClpQGQKjd5KC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def test_model_1stage_multi_threshold(model, test_loader, device, super_threshold=0.7, sub_threshold=0.6, save_to_csv=True, save_path='test_predictions.csv'):\n",
        "    model.eval()\n",
        "    test_predictions = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
        "\n",
        "    novel_super_idx = 3\n",
        "    novel_sub_idx = 87\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, img_names) in enumerate(test_loader):\n",
        "            images = images.to(device)\n",
        "\n",
        "            super_logits, sub_logits, super_novel_logits, sub_novel_logits = model(images)\n",
        "\n",
        "            super_probs = F.softmax(super_logits, dim=1)\n",
        "            sub_probs = F.softmax(sub_logits, dim=1)\n",
        "\n",
        "            super_max_prob, super_pred = torch.max(super_probs, dim=1)\n",
        "            sub_max_prob, sub_pred = torch.max(sub_probs, dim=1)\n",
        "\n",
        "            super_novel_score = torch.sigmoid(super_novel_logits.squeeze()).item()\n",
        "            sub_novel_score = torch.sigmoid(sub_novel_logits.squeeze()).item()\n",
        "\n",
        "            if super_max_prob.item() < super_threshold or super_novel_score > 0.5:\n",
        "                final_super = novel_super_idx\n",
        "                final_sub = novel_sub_idx\n",
        "            elif sub_max_prob.item() < sub_threshold or sub_novel_score > 0.5:\n",
        "                final_super = super_pred.item()\n",
        "                final_sub = novel_sub_idx\n",
        "            else:\n",
        "                final_super = super_pred.item()\n",
        "                final_sub = sub_pred.item()\n",
        "\n",
        "            test_predictions['image'].append(img_names[0])\n",
        "            test_predictions['superclass_index'].append(final_super)\n",
        "            test_predictions['subclass_index'].append(final_sub)\n",
        "\n",
        "    test_predictions = pd.DataFrame(test_predictions)\n",
        "\n",
        "    if save_to_csv:\n",
        "        test_predictions.to_csv(save_path, index=False)\n",
        "        print(f\" Test predictions saved to {save_path}\")\n",
        "\n",
        "    return test_predictions\n"
      ],
      "metadata": {
        "id": "TfHxZmPKgRDY"
      },
      "id": "TfHxZmPKgRDY",
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = test_model_1stage_multi_threshold(\n",
        "    model,\n",
        "    open_set_test_loader,\n",
        "    device,\n",
        "    super_threshold=0.9,\n",
        "    sub_threshold=0.75,\n",
        "    save_to_csv=True,\n",
        "    save_path='test_predictions_multi_threshold.csv'\n",
        ")\n"
      ],
      "metadata": {
        "id": "FoTY7Ig1gSoX"
      },
      "id": "FoTY7Ig1gSoX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor, ToPILImage\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "# Load base data\n",
        "train_ann_df = pd.read_csv(f'{data_dir}/train_data.csv')\n",
        "test_ann_df = pd.read_csv(f'{data_dir}/train_data.csv')  # (if no separate test set)\n",
        "super_map_df = pd.read_csv(f'{data_dir}/superclass_mapping.csv')\n",
        "sub_map_df = pd.read_csv(f'{data_dir}/subclass_mapping.csv')\n",
        "\n",
        "train_img_dir = '/content/train_images'\n",
        "test_img_dir = '/content/train_images'\n",
        "\n",
        "# Image transform\n",
        "image_preprocessing = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5] * 3, [0.5] * 3)\n",
        "])\n",
        "\n",
        "# Annotate original known data\n",
        "train_ann_df['is_super_novel'] = 0\n",
        "train_ann_df['is_sub_novel'] = 0\n",
        "\n",
        "# Only known data\n",
        "full_dataset = MultiClassImageDatasetWithNovelty(\n",
        "    ann_df=train_ann_df,\n",
        "    super_map_df=super_map_df,\n",
        "    sub_map_df=sub_map_df,\n",
        "    transform=image_preprocessing\n",
        ")\n",
        "\n",
        "torch.manual_seed(42)\n",
        "\n",
        "train_size = int(0.8 * len(full_dataset))\n",
        "val_size = int(0.1 * len(full_dataset))\n",
        "test_size = len(full_dataset) - train_size - val_size\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(\n",
        "    full_dataset, [train_size, val_size, test_size]\n",
        ")\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=2,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False\n",
        ")\n"
      ],
      "metadata": {
        "id": "qn9FF-KXg-Ov"
      },
      "id": "qn9FF-KXg-Ov",
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_validate_pure(model, train_loader, val_loader, optimizer,\n",
        "                       criterion, super_novel_criterion, sub_novel_criterion,\n",
        "                       device, num_epochs=10, warmup_epochs=5):\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n Epoch {epoch+1}/{num_epochs}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "        correct_super_train, correct_sub_train = 0, 0\n",
        "        correct_supernovel_train, correct_subnovel_train = 0, 0\n",
        "        total_train = 0\n",
        "\n",
        "        for i, (images, super_idx, sub_idx, is_super_novel, is_sub_novel) in enumerate(train_loader):\n",
        "            images = images.to(device)\n",
        "            super_idx = super_idx.to(device)\n",
        "            sub_idx = sub_idx.to(device)\n",
        "            is_super_novel = is_super_novel.float().to(device)\n",
        "            is_sub_novel = is_sub_novel.float().to(device)\n",
        "\n",
        "            out_super, out_sub, out_super_novel, out_sub_novel = model(images)\n",
        "\n",
        "            if epoch < warmup_epochs:\n",
        "                # Warmup phase: only classification losses\n",
        "                loss = criterion(out_super, super_idx) + criterion(out_sub, sub_idx)\n",
        "            else:\n",
        "                # After warmup: add novelty losses\n",
        "                loss = (\n",
        "                    criterion(out_super, super_idx) +\n",
        "                    criterion(out_sub, sub_idx) +\n",
        "                    super_novel_criterion(out_super_novel.squeeze(), is_super_novel) +\n",
        "                    sub_novel_criterion(out_sub_novel.squeeze(), is_sub_novel)\n",
        "                )\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pred_super = out_super.argmax(1)\n",
        "            pred_sub = out_sub.argmax(1)\n",
        "            pred_supernovel = (torch.sigmoid(out_super_novel.squeeze()) > 0.5).long()\n",
        "            pred_subnovel = (torch.sigmoid(out_sub_novel.squeeze()) > 0.5).long()\n",
        "\n",
        "            correct_super_train += (pred_super == super_idx).sum().item()\n",
        "            correct_sub_train += (pred_sub == sub_idx).sum().item()\n",
        "            correct_supernovel_train += (pred_supernovel == is_super_novel.long()).sum().item()\n",
        "            correct_subnovel_train += (pred_subnovel == is_sub_novel.long()).sum().item()\n",
        "\n",
        "            total_train += images.size(0)\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        print(f\" Epoch {epoch+1} Train Summary: Loss = {train_loss/len(train_loader):.4f} | \"\n",
        "              f\"Super Acc = {correct_super_train/total_train:.4f} | \"\n",
        "              f\"Sub Acc = {correct_sub_train/total_train:.4f} | \"\n",
        "              f\"SuperNovel Acc = {correct_supernovel_train/total_train:.4f} | \"\n",
        "              f\"SubNovel Acc = {correct_subnovel_train/total_train:.4f}\")\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        correct_super_val, correct_sub_val = 0, 0\n",
        "        correct_supernovel_val, correct_subnovel_val = 0, 0\n",
        "        total_val = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for i, (images, super_idx, sub_idx, is_super_novel, is_sub_novel) in enumerate(val_loader):\n",
        "                images = images.to(device)\n",
        "                super_idx = super_idx.to(device)\n",
        "                sub_idx = sub_idx.to(device)\n",
        "                is_super_novel = is_super_novel.float().to(device)\n",
        "                is_sub_novel = is_sub_novel.float().to(device)\n",
        "\n",
        "                out_super, out_sub, out_super_novel, out_sub_novel = model(images)\n",
        "\n",
        "                if epoch < warmup_epochs:\n",
        "                    loss = criterion(out_super, super_idx) + criterion(out_sub, sub_idx)\n",
        "                else:\n",
        "                    loss = (\n",
        "                        criterion(out_super, super_idx) +\n",
        "                        criterion(out_sub, sub_idx) +\n",
        "                        super_novel_criterion(out_super_novel.squeeze(), is_super_novel) +\n",
        "                        sub_novel_criterion(out_sub_novel.squeeze(), is_sub_novel)\n",
        "                    )\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                pred_super = out_super.argmax(1)\n",
        "                pred_sub = out_sub.argmax(1)\n",
        "                pred_supernovel = (torch.sigmoid(out_super_novel.squeeze()) > 0.5).long()\n",
        "                pred_subnovel = (torch.sigmoid(out_sub_novel.squeeze()) > 0.5).long()\n",
        "\n",
        "                correct_super_val += (pred_super == super_idx).sum().item()\n",
        "                correct_sub_val += (pred_sub == sub_idx).sum().item()\n",
        "                correct_supernovel_val += (pred_supernovel == is_super_novel.long()).sum().item()\n",
        "                correct_subnovel_val += (pred_subnovel == is_sub_novel.long()).sum().item()\n",
        "\n",
        "                total_val += images.size(0)\n",
        "\n",
        "        print(f\" Epoch {epoch+1} Val Summary: Loss = {val_loss/len(val_loader):.4f} | \"\n",
        "              f\"Super Acc = {correct_super_val/total_val:.4f} | \"\n",
        "              f\"Sub Acc = {correct_sub_val/total_val:.4f} | \"\n",
        "              f\"SuperNovel Acc = {correct_supernovel_val/total_val:.4f} | \"\n",
        "              f\"SubNovel Acc = {correct_subnovel_val/total_val:.4f}\")\n",
        "        print(f\"Time: {time.time() - start_time:.2f}s\")\n"
      ],
      "metadata": {
        "id": "AT6JWo7GjBgA"
      },
      "id": "AT6JWo7GjBgA",
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Rebuild Model\n",
        "model = ViTMultiTaskWithNovelty().to(device)\n",
        "\n",
        "# 2. Rebuild Optimizer\n",
        "head_params = (\n",
        "    list(model.super_head.parameters()) +\n",
        "    list(model.sub_head.parameters()) +\n",
        "    list(model.super_novel_head.parameters()) +\n",
        "    list(model.sub_novel_head.parameters())\n",
        ")\n",
        "backbone_params = [\n",
        "    p for n, p in model.named_parameters()\n",
        "    if (\"blocks.8\" in n or \"blocks.9\" in n or \"blocks.10\" in n or \"blocks.11\" in n or \"norm\" in n)\n",
        "]\n",
        "optimizer = torch.optim.AdamW([\n",
        "    {'params': head_params, 'lr': 1e-3},\n",
        "    {'params': backbone_params, 'lr': 1e-5}\n",
        "])\n",
        "train_and_validate_pure(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    super_novel_criterion,\n",
        "    sub_novel_criterion,\n",
        "    device,\n",
        "    num_epochs=3,\n",
        "    warmup_epochs=5\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "miZpnip-hpHh",
        "outputId": "877a2628-6295-414d-d448-d90226f05501"
      },
      "id": "miZpnip-hpHh",
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Epoch 1/3\n",
            " Epoch 1 Train Summary: Loss = 0.9985 | Super Acc = 0.9738 | Sub Acc = 0.7845 | SuperNovel Acc = 0.5851 | SubNovel Acc = 0.7636\n",
            " Epoch 1 Val Summary: Loss = 0.2322 | Super Acc = 1.0000 | Sub Acc = 0.9252 | SuperNovel Acc = 0.5685 | SubNovel Acc = 0.7532\n",
            "Time: 14.57s\n",
            "\n",
            " Epoch 2/3\n",
            " Epoch 2 Train Summary: Loss = 0.1099 | Super Acc = 1.0000 | Sub Acc = 0.9744 | SuperNovel Acc = 0.5831 | SubNovel Acc = 0.7312\n",
            " Epoch 2 Val Summary: Loss = 0.1636 | Super Acc = 1.0000 | Sub Acc = 0.9427 | SuperNovel Acc = 0.5653 | SubNovel Acc = 0.7373\n",
            "Time: 14.96s\n",
            "\n",
            " Epoch 3/3\n",
            " Epoch 3 Train Summary: Loss = 0.0594 | Super Acc = 1.0000 | Sub Acc = 0.9881 | SuperNovel Acc = 0.5819 | SubNovel Acc = 0.7149\n",
            " Epoch 3 Val Summary: Loss = 0.1382 | Super Acc = 1.0000 | Sub Acc = 0.9506 | SuperNovel Acc = 0.5669 | SubNovel Acc = 0.7150\n",
            "Time: 14.81s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, test_loader, device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXcykzLikEbU",
        "outputId": "0260aa51-a9cd-4a8f-a256-44f9a1790622"
      },
      "id": "XXcykzLikEbU",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Evaluation Summary:\n",
            "   Superclass Accuracy      = 1.0000\n",
            "   Subclass Accuracy        = 0.9603\n",
            "   Super Novelty Accuracy   = 0.5714\n",
            "   Sub Novelty Accuracy     = 0.6762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = test_model_1stage_multi_threshold(\n",
        "    model,\n",
        "    open_set_test_loader,\n",
        "    device,\n",
        "    super_threshold=0.9,\n",
        "    sub_threshold=0.85,\n",
        "    save_to_csv=True,\n",
        "    save_path='test_predictions_multi_threshold.csv'\n",
        ")\n"
      ],
      "metadata": {
        "id": "NTQfD_ackHFo"
      },
      "id": "NTQfD_ackHFo",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_two_stage_pure(supernet, subnet, train_loader, optimizer_super, optimizer_sub, device,\n",
        "                    num_epochs=10, warmup_epochs=5):\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n Epoch {epoch+1}/{num_epochs}\")\n",
        "        supernet.train()\n",
        "        subnet.train()\n",
        "\n",
        "        total, correct_super, correct_sub = 0, 0, 0\n",
        "        correct_supernovel, correct_subnovel = 0, 0\n",
        "\n",
        "        for images, super_idx, sub_idx, is_super_novel, is_sub_novel in train_loader:\n",
        "            images = images.to(device)\n",
        "            super_idx = super_idx.to(device)\n",
        "            sub_idx = sub_idx.to(device)\n",
        "            is_super_novel = is_super_novel.float().to(device)\n",
        "            is_sub_novel = is_sub_novel.float().to(device)\n",
        "\n",
        "            # --- SuperNet forward ---\n",
        "            super_logits, super_novel = supernet(images)\n",
        "\n",
        "            if epoch < warmup_epochs:\n",
        "                super_loss = criterion(super_logits, super_idx)\n",
        "            else:\n",
        "                super_loss = (\n",
        "                    criterion(super_logits, super_idx) +\n",
        "                    bce(super_novel.squeeze(), is_super_novel)\n",
        "                )\n",
        "\n",
        "            optimizer_super.zero_grad()\n",
        "            super_loss.backward()\n",
        "            optimizer_super.step()\n",
        "\n",
        "            # --- SubNet forward (teacher forcing with GT super_idx) ---\n",
        "            super_onehot = F.one_hot(super_idx, num_classes=4).float().to(device)\n",
        "            sub_logits, sub_novel = subnet(images, super_onehot)\n",
        "\n",
        "            if epoch < warmup_epochs:\n",
        "                sub_loss = criterion(sub_logits, sub_idx)\n",
        "            else:\n",
        "                sub_loss = (\n",
        "                    criterion(sub_logits, sub_idx) +\n",
        "                    bce(sub_novel.squeeze(), is_sub_novel)\n",
        "                )\n",
        "\n",
        "            optimizer_sub.zero_grad()\n",
        "            sub_loss.backward()\n",
        "            optimizer_sub.step()\n",
        "\n",
        "            # --- Metrics ---\n",
        "            pred_super = super_logits.argmax(1)\n",
        "            pred_sub = sub_logits.argmax(1)\n",
        "            pred_supernovel = (torch.sigmoid(super_novel.squeeze()) > 0.5).long()\n",
        "            pred_subnovel = (torch.sigmoid(sub_novel.squeeze()) > 0.5).long()\n",
        "\n",
        "            correct_super += (pred_super == super_idx).sum().item()\n",
        "            correct_sub += (pred_sub == sub_idx).sum().item()\n",
        "            correct_supernovel += (pred_supernovel == is_super_novel.long()).sum().item()\n",
        "            correct_subnovel += (pred_subnovel == is_sub_novel.long()).sum().item()\n",
        "            total += images.size(0)\n",
        "\n",
        "        print(f\" Super Acc = {correct_super/total:.4f} | Sub Acc = {correct_sub/total:.4f}\")\n",
        "        print(f\" SuperNovel Acc = {correct_supernovel/total:.4f} | SubNovel Acc = {correct_subnovel/total:.4f}\")\n"
      ],
      "metadata": {
        "id": "1ZuC-UgSlYDU"
      },
      "id": "1ZuC-UgSlYDU",
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "supernet = SuperNet().to(device)\n",
        "subnet = SubNet().to(device)\n",
        "\n",
        "optimizer_super = torch.optim.AdamW(supernet.parameters(), lr=1e-4)\n",
        "optimizer_sub = torch.optim.AdamW(subnet.parameters(), lr=1e-4)\n",
        "\n",
        "train_two_stage_pure(\n",
        "    supernet,\n",
        "    subnet,\n",
        "    train_loader,\n",
        "    optimizer_super,\n",
        "    optimizer_sub,\n",
        "    device,\n",
        "    num_epochs=5,\n",
        "    warmup_epochs=5\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "s8lo9XfLlcg0"
      },
      "id": "s8lo9XfLlcg0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_two_stage(supernet, subnet, test_loader, device)"
      ],
      "metadata": {
        "id": "cJ0gOIQplyUL"
      },
      "id": "cJ0gOIQplyUL",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def test_model_2stage_multi_threshold(supernet, subnet, test_loader, device,\n",
        "                                       super_threshold=0.75, sub_threshold=0.65,\n",
        "                                       save_to_csv=True, save_path='test_predictions.csv'):\n",
        "    supernet.eval()\n",
        "    subnet.eval()\n",
        "\n",
        "    test_predictions = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
        "\n",
        "    novel_super_idx = 3\n",
        "    novel_sub_idx = 87\n",
        "    num_super_classes = 4\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, img_names) in enumerate(test_loader):\n",
        "            images = images.to(device)\n",
        "\n",
        "            # ----- Stage 1: Superclass prediction -----\n",
        "            super_logits, super_novel_logits = supernet(images)\n",
        "\n",
        "            super_probs = F.softmax(super_logits, dim=1)\n",
        "            super_max_prob, super_pred = torch.max(super_probs, dim=1)\n",
        "\n",
        "            super_novel_score = torch.sigmoid(super_novel_logits.squeeze()).item()\n",
        "\n",
        "            if super_max_prob.item() < super_threshold or super_novel_score > 0.5:\n",
        "                final_super = novel_super_idx\n",
        "                final_sub = novel_sub_idx\n",
        "            else:\n",
        "                final_super = super_pred.item()\n",
        "\n",
        "                # ----- Stage 2: Subclass prediction -----\n",
        "                super_onehot = F.one_hot(torch.tensor([final_super], device=device), num_classes=num_super_classes).float()\n",
        "                sub_logits, sub_novel_logits = subnet(images, super_onehot)\n",
        "\n",
        "\n",
        "                sub_probs = F.softmax(sub_logits, dim=1)\n",
        "                sub_max_prob, sub_pred = torch.max(sub_probs, dim=1)\n",
        "\n",
        "                sub_novel_score = torch.sigmoid(sub_novel_logits.squeeze()).item()\n",
        "\n",
        "                if sub_max_prob.item() < sub_threshold or sub_novel_score > 0.5:\n",
        "                    final_sub = novel_sub_idx\n",
        "                else:\n",
        "                    final_sub = sub_pred.item()\n",
        "\n",
        "            test_predictions['image'].append(img_names[0])\n",
        "            test_predictions['superclass_index'].append(final_super)\n",
        "            test_predictions['subclass_index'].append(final_sub)\n",
        "\n",
        "    test_predictions = pd.DataFrame(test_predictions)\n",
        "\n",
        "    if save_to_csv:\n",
        "        test_predictions.to_csv(save_path, index=False)\n",
        "        print(f\" 2-stage multi-threshold test predictions saved to {save_path}\")\n",
        "\n",
        "    return test_predictions\n"
      ],
      "metadata": {
        "id": "-ViB9-00mULT"
      },
      "id": "-ViB9-00mULT",
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = test_model_2stage_multi_threshold(\n",
        "    supernet,\n",
        "    subnet,\n",
        "    open_set_test_loader,\n",
        "    device,\n",
        "    super_threshold=0.75,\n",
        "    sub_threshold=0.65,\n",
        "    save_to_csv=True,\n",
        "    save_path='test_predictions_2stage_multi_threshold.csv'\n",
        ")\n"
      ],
      "metadata": {
        "id": "1JR8IGUImoYk"
      },
      "id": "1JR8IGUImoYk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import timm\n",
        "import torch.nn as nn\n",
        "\n",
        "import timm\n",
        "import torch.nn as nn\n",
        "\n",
        "class TinyViTMultiTaskNoNoveltyWithDropout(nn.Module):\n",
        "    def __init__(self, dropout_rate=0.5):\n",
        "        super().__init__()\n",
        "        self.base = timm.create_model('vit_tiny_patch16_224', pretrained=True)\n",
        "        self.base.head = nn.Identity()\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        self.super_head = nn.Linear(self.base.num_features, 4)\n",
        "        self.sub_head = nn.Linear(self.base.num_features, 88)\n",
        "\n",
        "        for param in self.base.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        for name, param in self.base.named_parameters():\n",
        "            if \"blocks.8\" in name or \"blocks.9\" in name or \"blocks.10\" in name or \"blocks.11\" in name or \"norm\" in name:\n",
        "                param.requires_grad = True\n",
        "\n",
        "    def forward(self, x):\n",
        "        feats = self.base(x)\n",
        "        feats = self.dropout(feats)\n",
        "\n",
        "        return self.super_head(feats), self.sub_head(feats)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y_GnJP4YoxXT"
      },
      "id": "y_GnJP4YoxXT",
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import StepLR\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n"
      ],
      "metadata": {
        "id": "tOKLHNMWp9xp"
      },
      "id": "tOKLHNMWp9xp",
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_validate_pure(model, train_loader, val_loader, optimizer, criterion, device, num_epochs=15, scheduler=None):\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\n Epoch {epoch+1}/{num_epochs}\")\n",
        "        start_time = time.time()\n",
        "\n",
        "        model.train()\n",
        "        total_train = 0\n",
        "        correct_super_train, correct_sub_train = 0, 0\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for images, super_idx, sub_idx, _, _ in train_loader:\n",
        "            images = images.to(device)\n",
        "            super_idx = super_idx.to(device)\n",
        "            sub_idx = sub_idx.to(device)\n",
        "\n",
        "            out_super, out_sub = model(images)\n",
        "\n",
        "            loss = criterion(out_super, super_idx) + criterion(out_sub, sub_idx)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            pred_super = out_super.argmax(1)\n",
        "            pred_sub = out_sub.argmax(1)\n",
        "\n",
        "            correct_super_train += (pred_super == super_idx).sum().item()\n",
        "            correct_sub_train += (pred_sub == sub_idx).sum().item()\n",
        "            total_train += images.size(0)\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step()\n",
        "\n",
        "        print(f\" Train Loss: {train_loss/len(train_loader):.4f} | Super Acc: {correct_super_train/total_train:.4f} | Sub Acc: {correct_sub_train/total_train:.4f}\")\n",
        "\n",
        "        # ---- VALIDATION ----\n",
        "        model.eval()\n",
        "        total_val = 0\n",
        "        correct_super_val, correct_sub_val = 0, 0\n",
        "        val_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for images, super_idx, sub_idx, _, _ in val_loader:\n",
        "                images = images.to(device)\n",
        "                super_idx = super_idx.to(device)\n",
        "                sub_idx = sub_idx.to(device)\n",
        "\n",
        "                out_super, out_sub = model(images)\n",
        "\n",
        "                loss = criterion(out_super, super_idx) + criterion(out_sub, sub_idx)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                pred_super = out_super.argmax(1)\n",
        "                pred_sub = out_sub.argmax(1)\n",
        "\n",
        "                correct_super_val += (pred_super == super_idx).sum().item()\n",
        "                correct_sub_val += (pred_sub == sub_idx).sum().item()\n",
        "                total_val += images.size(0)\n",
        "\n",
        "        print(f\"ðŸ“Š Val Loss: {val_loss/len(val_loader):.4f} | Super Acc: {correct_super_val/total_val:.4f} | Sub Acc: {correct_sub_val/total_val:.4f}\")\n",
        "        print(f\"â±ï¸ Time: {time.time() - start_time:.2f}s\")\n"
      ],
      "metadata": {
        "id": "ffAWouqAri00"
      },
      "id": "ffAWouqAri00",
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Rebuild Model\n",
        "model = TinyViTMultiTaskNoNoveltyWithDropout().to(device)\n",
        "\n",
        "# 2. Rebuild Optimizer\n",
        "head_params = (\n",
        "    list(model.super_head.parameters()) +\n",
        "    list(model.sub_head.parameters())\n",
        ")\n",
        "backbone_params = [\n",
        "    p for n, p in model.named_parameters()\n",
        "    if (\"blocks.8\" in n or \"blocks.9\" in n or \"blocks.10\" in n or \"blocks.11\" in n or \"norm\" in n)\n",
        "]\n",
        "optimizer = torch.optim.AdamW([\n",
        "    {'params': head_params, 'lr': 1e-4, 'weight_decay': 0.01},\n",
        "    {'params': backbone_params, 'lr': 1e-6, 'weight_decay': 0.01}\n",
        "])\n",
        "scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
        "\n",
        "train_and_validate_pure(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    device,\n",
        "    num_epochs=8,\n",
        "    scheduler=scheduler\n",
        ")\n"
      ],
      "metadata": {
        "id": "OWvhbV5Ppd5z"
      },
      "id": "OWvhbV5Ppd5z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_validate_pure(\n",
        "    model,\n",
        "    train_loader,\n",
        "    val_loader,\n",
        "    optimizer,\n",
        "    criterion,\n",
        "    device,\n",
        "    num_epochs=12,\n",
        "    scheduler=scheduler\n",
        ")"
      ],
      "metadata": {
        "id": "2ez3wKbetxth"
      },
      "id": "2ez3wKbetxth",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_pure(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct_super = 0\n",
        "    correct_sub = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, super_idx, sub_idx, _, _ in dataloader:\n",
        "            images = images.to(device)\n",
        "            super_idx = super_idx.to(device)\n",
        "            sub_idx = sub_idx.to(device)\n",
        "\n",
        "            out_super, out_sub = model(images)\n",
        "\n",
        "            pred_super = out_super.argmax(1)\n",
        "            pred_sub = out_sub.argmax(1)\n",
        "\n",
        "            correct_super += (pred_super == super_idx).sum().item()\n",
        "            correct_sub += (pred_sub == sub_idx).sum().item()\n",
        "            total += images.size(0)\n",
        "\n",
        "    super_acc = correct_super / total\n",
        "    sub_acc = correct_sub / total\n",
        "\n",
        "    print(f\"ðŸ§ª Evaluation:\")\n",
        "    print(f\"   Superclass Accuracy = {super_acc:.4f}\")\n",
        "    print(f\"   Subclass Accuracy   = {sub_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "UIWVaQ_Ir2WT"
      },
      "id": "UIWVaQ_Ir2WT",
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_pure(model, test_loader, device)"
      ],
      "metadata": {
        "id": "6LL5Hw8uqV9V"
      },
      "id": "6LL5Hw8uqV9V",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def test_model_1stage_pure(model, test_loader, device,\n",
        "                            super_threshold=0.75, sub_threshold=0.65,\n",
        "                            save_to_csv=True, save_path='test_predictions_pure.csv'):\n",
        "    model.eval()\n",
        "    test_predictions = {'image': [], 'superclass_index': [], 'subclass_index': []}\n",
        "\n",
        "    novel_super_idx = 3\n",
        "    novel_sub_idx = 87\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (images, img_names) in enumerate(test_loader):\n",
        "            images = images.to(device)\n",
        "\n",
        "            out_super, out_sub = model(images)\n",
        "\n",
        "            super_probs = F.softmax(out_super, dim=1)\n",
        "            super_max_prob, super_pred = torch.max(super_probs, dim=1)\n",
        "\n",
        "            sub_probs = F.softmax(out_sub, dim=1)\n",
        "            sub_max_prob, sub_pred = torch.max(sub_probs, dim=1)\n",
        "\n",
        "            # Decision based on softmax confidence\n",
        "            if super_max_prob.item() < super_threshold:\n",
        "                final_super = novel_super_idx\n",
        "                final_sub = novel_sub_idx\n",
        "            else:\n",
        "                final_super = super_pred.item()\n",
        "\n",
        "                if sub_max_prob.item() < sub_threshold:\n",
        "                    final_sub = novel_sub_idx\n",
        "                else:\n",
        "                    final_sub = sub_pred.item()\n",
        "\n",
        "            test_predictions['image'].append(img_names[0])\n",
        "            test_predictions['superclass_index'].append(final_super)\n",
        "            test_predictions['subclass_index'].append(final_sub)\n",
        "\n",
        "    test_predictions = pd.DataFrame(test_predictions)\n",
        "\n",
        "    if save_to_csv:\n",
        "        test_predictions.to_csv(save_path, index=False)\n",
        "        print(f\" Test predictions saved to {save_path}\")\n",
        "\n",
        "    return test_predictions\n"
      ],
      "metadata": {
        "id": "W-2kHtIvuyVH"
      },
      "id": "W-2kHtIvuyVH",
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_predictions = test_model_1stage_pure(\n",
        "    model,\n",
        "    open_set_test_loader,\n",
        "    device,\n",
        "    super_threshold=0.75,\n",
        "    sub_threshold=0.65,\n",
        "    save_to_csv=True,\n",
        "    save_path='test_predictions_1stage_pure.csv'\n",
        ")\n"
      ],
      "metadata": {
        "id": "tQIGm-yQu0Vw"
      },
      "id": "tQIGm-yQu0Vw",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}